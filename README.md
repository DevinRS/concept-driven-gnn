# Concept-Driven Disentanglement for Interpretable SC-FC Coupling

This repository contains the code for the paper: **"A Concept-Driven Disentanglement Framework for Interpretable Graph Neural Networks in Structure-Function Coupling"**.

## ðŸ“„ Abstract
Graph Neural Networks (GNNs) excel at predicting brain functional connectivity (FC) from structural connectivity (SC) but often lack interpretability. We propose a **Concept-Driven Disentanglement Framework** that uses an ensemble of architecturally biased GNN branches. This design enforces disentangled embeddings (e.g., "Strong vs. Weak" connections) and allows for quantitative hypothesis testing using SHAP.

### Key Findings
* **Framework Verification:** The framework successfully **disentangles structural drivers**, allowing for specific hypothesis testing (e.g., determining the exact predictive weight of competing structural concepts).
* **Generalizability & Null Testing:** We demonstrated the framework's flexibility by evaluating three distinct structural hypotheses. In all cases, observed SHAP ratios significantly deviated from the null distribution generated by permutation testing ($N=100$):
    * **Strong vs. Weak Connections:** Strong connections formed the stable backbone of static FC prediction. Despite representing a minority of the input (~19%), they accounted for the vast majority of predictive importance (SHAP Ratio = 75.5). This was a massive outlier compared to the random null distribution (Mean = 0.42, SD = 0.27, $p < 0.001$).
    * **Short vs. Long Range:** The model attributed disproportionate importance to **short-range connections** (SHAP Ratio = 0.17). This was a significant outlier compared to the random null distribution (Mean = 1.13, SD = 0.56, $p < 0.05$), confirming the dominance of local topology in static FC prediction.
    * **Normal vs. Outlier:** Despite constituting only ~4% of the data, rare **"Outlier" connections** (weights $>2\sigma$) contributed almost equally to prediction as "Normal" connections (SHAP Ratio = 0.97). This significantly exceeded the null expectation (Mean = 0.36, SD = 0.21, $p < 0.05$), indicating that high-strength hubs play a critical role despite their sparsity.

## ðŸ§  Framework
The model filters the input SC matrix based on predefined neuroscientific concepts before passing them to specialized GNN branches.

![Framework Overview](figures/Figure%201.png)

## ðŸ› ï¸ Usage

The project pipeline is divided into four sequential notebooks located in the `notebooks/` directory. You can run these directly in Google Colab.

> **Quick Start:** For a full demo run, execute the notebooks in order (1 $\rightarrow$ 4). Ensure the anonymized `.npy` data files (provided in the repo) are in your working directory.

### 1. `1_DataVisualization.ipynb`
**Understanding the Input Data**
* **Function:** Visualizes the core matrices from the MICA-MICS dataset used in the study.
* **Key Operations:**
    * Loads Structural (SC), Functional (FC), and Euclidean Distance matrices.
    * Performs **Subject-wise Min-Max Normalization** to standardize inputs while preserving individual topology.
* **Visuals:** Generates heatmaps to verify SC sparsity and FC modular structure.

### 2. `2_ModelBaseline.ipynb`
**Benchmarking with Standard GNNs**
* **Function:** Establishes a performance baseline using a standard "Black Box" Graph Neural Network.
* **Method:** Replicates state-of-the-art approaches (e.g., *Chen et al.*) by mapping SC to FC without explicit conceptual disentanglement.
* **Architecture:** 2-layer GCN Encoder $\rightarrow$ Edge Regression MLP Decoder.
* **Metric:** Calculates Pearson correlation ($r$) at both individual and group levels.

### 3. `3_ModelConcept.ipynb`
**The Concept-Driven Framework (Novelty)**
* **Function:** Trains the Interpretable Ensemble GNN to test specific structural hypotheses (e.g., "Do outliers drive FC?").
* **Key Operations:**
    * **Mask Generation:** filters edges into competing concepts (e.g., "Normal" vs. "Outlier" at $\pm 2\sigma$).
    * **Ensemble Training:** Uses **Inverse Frequency Weighted Loss** to prevent bias towards majority concepts.
    * **SHAP Analysis:** Quantifies the exact predictive ratio of Concept A vs. Concept B using DeepExplainer.

### 4. `4_NullTesting.ipynb`
**Statistical Validation**
* **Function:** Validates that the SHAP findings are statistically significant and not artifacts of random chance.
* **Key Operations:**
    * **Null Distribution:** Generates a baseline of SHAP ratios by training the model on **randomized masks** ($N=100$ permutations).
    * **Hypothesis Testing:** Compares the actual SHAP ratio (from Notebook 3) against the null distribution to calculate $p$-values.
* **Replicability:** Visualizes the full 100-iteration experiment results using the provided `results_null_distribution.csv`.

## ðŸ“‚ Dataset
This project uses the **MICA-MICS dataset**. 
- We provide the processed datasets in `notebooks/Dataset/` which contain the $116 \times 116$ Schaefer parcellated matrices used in the study.
- Raw data must be requested/downloaded from the [MICA-MICS repository](https://data.mics.mcgill.ca/).

## ðŸ“š Citation
If you use this code or framework in your research, please cite our preprint:

**Text:**
Setiawan, D., Shomaji, S., GoÃ±i, J., & Ashourvan, A. (2025). A Concept-Driven Disentanglement Framework for Interpretable Graph Neural Networks in Structure-Function Coupling. *bioRxiv*. doi:10.64898/2025.12.15.694495

**BibTeX:**
```bibtex
@article{setiawan2025concept,
  title={A Concept-Driven Disentanglement Framework for Interpretable Graph Neural Networks in Structure-Function Coupling},
  author={Setiawan, Devin and Shomaji, Sumaiya and Go{\~n}i, Joaqu{\'i}n and Ashourvan, Arian},
  journal={bioRxiv},
  year={2025},
  doi={10.64898/2025.12.15.694495},
  url={[https://doi.org/10.64898/2025.12.15.694495](https://doi.org/10.64898/2025.12.15.694495)}
}
